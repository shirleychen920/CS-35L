Lab7    --By Haojie Chen
------------------------------------------------
$ export PATH=/usr/local/cs/bin:$PATH
Add /usr/local/cs/bin to PATH since the latest GNU sort has been installed
here.

$ sort --version
To make sure I am using a new enough version of sort. The version I am using
is 8.23.

$ od -An -f -N 80000000 < /dev/urandom | tr -s ' ' '\n' > random.txt
Generate a file called random.txt containing 10,000,000 random double-precision
floating point numbers. Since each number is 8 bytes, we need 80,000,000 bytes.

$ time -p sort -g --parallel=Num random.txt > /dev/null
Time the sort command on file random.txt. Num represents the number of threads
runing concurrently.

I timed 1, 2, 4 and 8 threads repectivesly, results as following:
1 thread:
real 210.64
user 207.21
sys 0.39

2 threads:
real 109.55
user 208.02
sys 0.55

4 threads:
real 66.63
user 220.01
sys 0.54

8 threads:
real 45.50
user 237.40
sys 0.64


From the results, we can tell that when we double the number of threads, the
time it takes to sort reduces by roughly half. When using more threads to sort,
the original workload is divided into several poritions and they run concurrently.
Parallel processing decreases the working time and makes the task more efficient.
